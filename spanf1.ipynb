{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import BertForTokenClassification\n",
    "import utils.NERutils as nu\n",
    "import utils.QueryUtils as q\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define tokenizer\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# Load data\n",
    "train_path = \"data/BIOtrain.parquet\"\n",
    "dev_path = \"data/BIOdev.parquet\"\n",
    "test_path = \"data/BIOtest.parquet\"\n",
    "\n",
    "FILTER = None\n",
    "\n",
    "train_dataset = nu.NERdataset(dataset_path=train_path, tokenizer=bert_tokenizer, filter=FILTER)\n",
    "dev_dataset = nu.NERdataset(dataset_path=dev_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "test_dataset = nu.NERdataset(dataset_path=test_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Config\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_config = AutoConfig.from_pretrained(\n",
    "    bert_model_name, \n",
    "    num_labels=len(train_dataset.tags), \n",
    "    id2label=train_dataset.index2tag, \n",
    "    label2id=train_dataset.tag2index\n",
    ")\n",
    "\n",
    "# initialise model\n",
    "model = BertForTokenClassification.from_pretrained(bert_model_name, config=bert_config, tags=train_dataset.tags, verbose=True).to(device)\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(\"Trained_models/checkpoint_trained_model.pt\", map_location=device))\n",
    "\n",
    "# Evaluate model\n",
    "preds, targets = nu.evaluate_model(model=model, dataloader=dev_loader, device=device)\n",
    "\n",
    "# Convert ids to tags\n",
    "preds = [*map(train_dataset.index2tag.get, list(preds))]\n",
    "golds = [*map(train_dataset.index2tag.get, list(targets))]\n",
    "\n",
    "f1score = nu.getF1ScoreFromLists(golds=golds, preds=preds)\n",
    "print(f\"{f1score = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
