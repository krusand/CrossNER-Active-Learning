{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 26%|██▌       | 48/183 [00:55<02:36,  1.16s/it]"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import BertForTokenClassification\n",
    "import utils.NERutils as nu\n",
    "import utils.QueryUtils as q\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define tokenizer\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# Load data\n",
    "train_path = \"data/BIOtrain.parquet\"\n",
    "dev_path = \"data/BIOdev.parquet\"\n",
    "test_path = \"data/BIOtest.parquet\"\n",
    "\n",
    "FILTER = None\n",
    "\n",
    "train_dataset = nu.NERdataset(dataset_path=train_path, tokenizer=bert_tokenizer, filter=FILTER)\n",
    "dev_dataset = nu.NERdataset(dataset_path=dev_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "test_dataset = nu.NERdataset(dataset_path=test_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Config\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_config = AutoConfig.from_pretrained(\n",
    "    bert_model_name, \n",
    "    num_labels=len(train_dataset.tags), \n",
    "    id2label=train_dataset.index2tag, \n",
    "    label2id=train_dataset.tag2index\n",
    ")\n",
    "\n",
    "# initialise model\n",
    "model = BertForTokenClassification.from_pretrained(bert_model_name, config=bert_config, tags=train_dataset.tags, verbose=True).to(device)\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(\"Trained_models/checkpoint_all_data.pt\", map_location=device))\n",
    "\n",
    "# Evaluate model\n",
    "preds, targets = nu.evaluate_model(model=model, dataloader=test_loader, device=device)\n",
    "\n",
    "# Convert ids to tags\n",
    "preds = [*map(train_dataset.index2tag.get, list(preds))]\n",
    "golds = [*map(train_dataset.index2tag.get, list(targets))]\n",
    "\n",
    "f1score = nu.getF1ScoreFromLists(golds=golds, preds=preds)\n",
    "print(f\"{f1score = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
