{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'batc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained_models/checkpoint_trained_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m preds, targets \u001b[38;5;241m=\u001b[39m \u001b[43mnu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Convert ids to tags\u001b[39;00m\n\u001b[1;32m     63\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(train_dataset\u001b[38;5;241m.\u001b[39mindex2tag\u001b[38;5;241m.\u001b[39mget, \u001b[38;5;28mlist\u001b[39m(preds))]\n",
      "File \u001b[0;32m~/Documents/GitHub/CrossNER-Active-Learning/utils/NERutils.py:307\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m    303\u001b[0m batch_preds, batch_targets \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader),total \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatc\u001b[49m):\n\u001b[1;32m    308\u001b[0m         ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    309\u001b[0m         mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'batc'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import BertForTokenClassification\n",
    "import utils.NERutils as nu\n",
    "import utils.QueryUtils as q\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define tokenizer\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# Load data\n",
    "train_path = \"data/BIOtrain.parquet\"\n",
    "dev_path = \"data/BIOdev.parquet\"\n",
    "test_path = \"data/BIOtest.parquet\"\n",
    "\n",
    "FILTER = None\n",
    "\n",
    "train_dataset = nu.NERdataset(dataset_path=train_path, tokenizer=bert_tokenizer, filter=FILTER)\n",
    "dev_dataset = nu.NERdataset(dataset_path=dev_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "test_dataset = nu.NERdataset(dataset_path=test_path, tokenizer=bert_tokenizer, filter=FILTER,tags=train_dataset.tags, index2tag=train_dataset.index2tag, tag2index=train_dataset.tag2index)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Config\n",
    "bert_model_name = \"bert-base-multilingual-cased\"\n",
    "bert_config = AutoConfig.from_pretrained(\n",
    "    bert_model_name, \n",
    "    num_labels=len(train_dataset.tags), \n",
    "    id2label=train_dataset.index2tag, \n",
    "    label2id=train_dataset.tag2index\n",
    ")\n",
    "\n",
    "# initialise model\n",
    "model = BertForTokenClassification.from_pretrained(bert_model_name, config=bert_config, tags=train_dataset.tags, verbose=True).to(device)\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(\"Trained_models/checkpoint_trained_model.pt\", map_location=device))\n",
    "\n",
    "# Evaluate model\n",
    "preds, targets = nu.evaluate_model(model=model, dataloader=dev_loader, device=device)\n",
    "\n",
    "# Convert ids to tags\n",
    "preds = [*map(train_dataset.index2tag.get, list(preds))]\n",
    "golds = [*map(train_dataset.index2tag.get, list(targets))]\n",
    "\n",
    "f1score = nu.getF1ScoreFromLists(golds=golds, preds=preds)\n",
    "print(f\"{f1score = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
